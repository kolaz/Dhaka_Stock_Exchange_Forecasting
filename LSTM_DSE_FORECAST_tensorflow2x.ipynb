{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set The Model Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stock_Forecast(Instrument, TRIAL, PATIENCE, Back):\n",
    "    \n",
    "    # importing required libraries\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "    import tensorflow as tf\n",
    "    import keras\n",
    "    import random as rn\n",
    "    import os\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "    from tensorflow.keras import backend as K\n",
    "    from tensorflow.keras.models import Sequential, load_model\n",
    "    from tensorflow.keras.layers import LSTM, Dense, RepeatVector, Masking, TimeDistributed\n",
    "    from tensorflow.keras.utils import plot_model\n",
    "    from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "    \n",
    "    import plotly.offline as py\n",
    "    import plotly.graph_objs as go\n",
    "    py.init_notebook_mode(connected=True)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    \n",
    "    # stop posting the warning\n",
    "    os.environ[\"PYTHONHASHSEED\"] = \"0\"\n",
    "    import tensorflow.python.util.deprecation as deprecation\n",
    "    deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "    # Setting the seed for numpy-generated random numbers\n",
    "    np.random.seed(37)\n",
    "\n",
    "    # Setting the seed for python random numbers\n",
    "    rn.seed(1254)\n",
    "\n",
    "    # Setting the graph-level random seed. (tensorflow 2x)\n",
    "    tf.random.set_seed(89)\n",
    "    \n",
    "    # tensorflow 2x change\n",
    "    session_conf = tf.compat.v1.ConfigProto(\n",
    "        intra_op_parallelism_threads=1, inter_op_parallelism_threads=1\n",
    "    )\n",
    "\n",
    "    # Force Tensorflow to use a single thread (tensorflow 2x)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.reset_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=session_conf))\n",
    "\n",
    "    # read the data\n",
    "    d = pd.read_excel(\"Book3.xlsx\")\n",
    "\n",
    "    # remove leading and trainling blank spaces from column names\n",
    "    d.columns = d.columns.str.strip()\n",
    "\n",
    "    # remove leanding and trailing blank spaces from TRADING.CODEs\n",
    "    d[\"TRADING.CODE\"] = d[\"TRADING.CODE\"].str.strip()\n",
    "\n",
    "    # select the Instrument of your interest\n",
    "    df = d[d[\"TRADING.CODE\"] == Instrument]\n",
    "\n",
    "    # remove rows with invalid values\n",
    "    df = df[\n",
    "        ~(df[\"LTP\"] == 0)\n",
    "        | (df[\"HIGH\"] == 0)\n",
    "        | (df[\"LOW\"] == 0)\n",
    "        | (df[\"OPENP\"] == 0)\n",
    "        | (df[\"CLOSEP\"] == 0)\n",
    "    ]\n",
    "\n",
    "    # sort the data as per date\n",
    "    df = df.sort_values([\"DATE\"], ascending=True)\n",
    "\n",
    "    # keep only the required columns\n",
    "    clean_data = df[[\"DATE\", \"CLOSEP\"]]\n",
    "\n",
    "    # set the date column as index\n",
    "    clean_data.set_index([\"DATE\"], inplace=True)\n",
    "\n",
    "    # turn the column into a numpy array\n",
    "    close_price = clean_data.values\n",
    "\n",
    "    # set first 85% values as training data and the rest as test data\n",
    "    train = close_price[: int(len(close_price) * 0.85), :]\n",
    "    valid = close_price[int(len(close_price) * 0.85) :, :]\n",
    "\n",
    "    # scaling the values\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(close_price)\n",
    "\n",
    "    # creating x_train and y_train, seeting the array as 0 dimensional, each time x_train.append is giving 'Back' values with 0 dimension,then set each as\n",
    "    # rows\n",
    "    x_train, y_train = [], []\n",
    "    for i in range(Back, len(train)):\n",
    "        x_train.append(scaled_data[i - Back : i, 0])\n",
    "        y_train.append(scaled_data[i, 0])\n",
    "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "    # turn x_train as three dimensional\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "\n",
    "    # create and fit the LSTM network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # set name for the saved model\n",
    "    saved_model = Instrument + \"weights.hdf5\"\n",
    "    \n",
    "    # tell the model to minimize mape\n",
    "    model.compile(\n",
    "        loss=\"mean_absolute_percentage_error\", optimizer=\"adam\"\n",
    "    )  \n",
    "    \n",
    "    # tell the model to wait for the next PATIENCE model, if no improvement, stop\n",
    "    ks = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", mode=\"auto\", verbose=1, patience=PATIENCE\n",
    "    )  \n",
    "    \n",
    "    # ask to save the best model\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=saved_model, monitor=\"loss\", verbose=0, save_best_only=True\n",
    "    )  \n",
    "    \n",
    "    # now fit the model\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=TRIAL,\n",
    "        validation_split=0.1,\n",
    "        verbose=0,\n",
    "        callbacks=[ks, checkpointer],\n",
    "    )  \n",
    "    \n",
    "    # now the best model will be loaded from saved file\n",
    "    model = load_model(saved_model)  \n",
    "\n",
    "    # predicting values, using past 'Back' from the train data\n",
    "    inputs = clean_data.values[len(clean_data) - len(valid) - Back :]\n",
    "    inputs = inputs.reshape(-1, 1)\n",
    "    inputs = scaler.transform(inputs)\n",
    "\n",
    "    # creating X_test\n",
    "    X_test = []\n",
    "    for i in range(Back, inputs.shape[0]):\n",
    "        X_test.append(inputs[i - Back : i, 0])\n",
    "    X_test = np.array(X_test)\n",
    "\n",
    "    # turn X_test into 3 dimensional\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    # forecasting future values ie calculating y_test\n",
    "    closing_price = model.predict(X_test)\n",
    "    cl = closing_price\n",
    "\n",
    "    # turning the forecasting values back to original scale\n",
    "    closing_price = scaler.inverse_transform(closing_price)\n",
    "\n",
    "    # model evaluate\n",
    "    train_acc = model.evaluate(x_train, y_train, verbose=0)\n",
    "    test_acc = model.evaluate(X_test, cl, verbose=0)\n",
    "    # print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "\n",
    "    # calculating MAPE\n",
    "    rms = np.sqrt(np.mean(np.power((valid - closing_price), 2)))\n",
    "    mape = sum(abs(valid - closing_price) / abs(valid)) * 100 * (1 / len(valid))\n",
    "\n",
    "    # Plot out of sample forecast\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    train = clean_data[: int(len(close_price) * 0.85)]\n",
    "    valid = clean_data[int(len(close_price) * 0.85) :]\n",
    "    valid[\"Predictions\"] = closing_price\n",
    "    plt.plot(train[\"CLOSEP\"])\n",
    "    plt.plot(valid[[\"CLOSEP\", \"Predictions\"]])\n",
    "    plt.title(\"Out of Sample Forecast\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Train Set\", \"Test Set\", \"Forecasted Price\"], prop={\"size\":15})\n",
    "\n",
    "#### If you need the Plotly Interactive Chart ####\n",
    "#     trace1 = go.Scatter(x=train.index, y=train[\"CLOSEP\"], mode=\"lines\", name=\"Train Set\")\n",
    "#     trace2 = go.Scatter(x=valid.index, y=valid[\"CLOSEP\"], mode=\"lines\", name=\"Test Set\")\n",
    "#     trace3 = go.Scatter(x=valid.index, y=valid[\"Predictions\"], mode=\"lines\", name=\"Predicted Values\")\n",
    "#     data = [trace1, trace2, trace3]\n",
    "#     layout = go.Layout(title = \"Out of Sample Forecast\", \n",
    "#                   xaxis = dict(title = \"Date\"), \n",
    "#                   yaxis = dict(title = \"Price\"))\n",
    "#     fig_test = go.Figure(data = data, layout = layout)\n",
    "#     py.iplot(fig_test)\n",
    "    \n",
    "    print(\"The Root Mean Square of the Model is: %.3f\" % (rms))\n",
    "    print(\"The Mean Absolute Percentage Error of the Model is: %.3f\" % (mape))\n",
    "\n",
    "    # out of sample (beyond test set) forecast, next 30 business days\n",
    "    last_values = scaled_data[-Back:]  # take last 'Back' values\n",
    "    last_values = last_values.reshape((1, Back, 1))  # reshape\n",
    "    yhat = np.zeros(shape=(30, 1))\n",
    "\n",
    "    # run for loop for creating one forecast at a time and then use it to forecast the next\n",
    "    for i in range(0, 30):\n",
    "        yhat[i] = model.predict(last_values, verbose=0)\n",
    "        last_values = np.append(last_values, yhat[i])[-Back:].reshape(1, Back, 1)\n",
    "\n",
    "    yx = scaler.inverse_transform(yhat)  # inverse the variable transformation\n",
    "    yx = np.concatenate(yx).ravel().tolist()  # unlist the forecast data\n",
    "    yx = [round(w, 1) for w in yx]  # rounding the data to .10\n",
    "\n",
    "    # create the date index of the forecasted values\n",
    "    weekmask = \"Sun Mon Tue Wed Thu\"\n",
    "    custombday = pd.offsets.CustomBusinessDay(weekmask=weekmask)\n",
    "    pday = pd.bdate_range(\n",
    "        start=df.iloc[clean_data.shape[0] - 1, 0] + datetime.timedelta(days=1),\n",
    "        end=df.iloc[clean_data.shape[0] - 1, 0] + datetime.timedelta(days=365),\n",
    "        freq=custombday,\n",
    "    ).tolist()[0:30]\n",
    "\n",
    "    # turn the forecasted values into a dataframe\n",
    "    forecast_data = pd.DataFrame({\"Date\": pday, \"Forecast\": yx})\n",
    "    forecast_data.set_index(\"Date\", inplace=True)\n",
    "\n",
    "    # now plot the forecast along with the original data\n",
    "    comb_data = pd.merge(\n",
    "        valid, forecast_data, left_index=True, right_index=True, how=\"outer\"\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.plot(comb_data[[\"CLOSEP\", \"Forecast\"]])\n",
    "    plt.title(\"Future Value Forecast\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Forecasted Price\"], prop={\"size\":15})\n",
    "\n",
    "#### For Plotly Interactive Charts ####\n",
    "#     trace1 = go.Scatter(x=comb_data.index, y=comb_data[\"CLOSEP\"], mode = \"lines\", name = \"Actual Price\")\n",
    "#     trace2 = go.Scatter(x = comb_data.index, y = comb_data[\"Forecast\"], mode = \"lines\", name = \"Forecasted Values\")\n",
    "#     data = [trace1, trace2]\n",
    "#     layout = go.Layout(\n",
    "#         title = \"Future Value Forecast\", \n",
    "#         xaxis = dict(title = \"Date\"), \n",
    "#         yaxis = dict(title = \"Price\")\n",
    "#     )\n",
    "#     fig_forecast = go.Figure(data=data, layout=layout)\n",
    "#     py.iplot(fig_forecast)\n",
    "\n",
    "\n",
    "    # the forecasted data as a output\n",
    "    return forecast_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now set the Parameters and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00315: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/ipykernel_launcher.py:172: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Root Mean Square of the Model is: 0.765\n",
      "The Mean Absolute Percentage Error of the Model is: 1.726\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Forecast</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-26</th>\n",
       "      <td>30.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-29</th>\n",
       "      <td>30.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-30</th>\n",
       "      <td>30.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>30.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-01</th>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-02</th>\n",
       "      <td>31.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-05</th>\n",
       "      <td>31.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-06</th>\n",
       "      <td>31.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-07</th>\n",
       "      <td>31.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-08</th>\n",
       "      <td>32.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-09</th>\n",
       "      <td>32.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-12</th>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-13</th>\n",
       "      <td>33.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-14</th>\n",
       "      <td>34.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-15</th>\n",
       "      <td>35.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-16</th>\n",
       "      <td>35.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-19</th>\n",
       "      <td>36.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-20</th>\n",
       "      <td>37.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-21</th>\n",
       "      <td>37.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-22</th>\n",
       "      <td>37.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-23</th>\n",
       "      <td>37.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-26</th>\n",
       "      <td>37.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-27</th>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-28</th>\n",
       "      <td>36.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-29</th>\n",
       "      <td>35.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-30</th>\n",
       "      <td>34.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-03</th>\n",
       "      <td>34.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-04</th>\n",
       "      <td>33.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-05</th>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-06</th>\n",
       "      <td>32.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Forecast\n",
       "Date                \n",
       "2020-03-26      30.9\n",
       "2020-03-29      30.8\n",
       "2020-03-30      30.8\n",
       "2020-03-31      30.9\n",
       "2020-04-01      31.0\n",
       "2020-04-02      31.2\n",
       "2020-04-05      31.4\n",
       "2020-04-06      31.6\n",
       "2020-04-07      31.9\n",
       "2020-04-08      32.3\n",
       "2020-04-09      32.7\n",
       "2020-04-12      33.3\n",
       "2020-04-13      33.8\n",
       "2020-04-14      34.5\n",
       "2020-04-15      35.2\n",
       "2020-04-16      35.9\n",
       "2020-04-19      36.6\n",
       "2020-04-20      37.2\n",
       "2020-04-21      37.6\n",
       "2020-04-22      37.9\n",
       "2020-04-23      37.8\n",
       "2020-04-26      37.5\n",
       "2020-04-27      37.0\n",
       "2020-04-28      36.3\n",
       "2020-04-29      35.6\n",
       "2020-04-30      34.9\n",
       "2020-05-03      34.3\n",
       "2020-05-04      33.8\n",
       "2020-05-05      33.3\n",
       "2020-05-06      32.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instrument = input Instrument Name\n",
    "# TRIAL = number of Epoch (trials),\n",
    "# PATIENCE = after how many trials without any improvement in result the system should stop trial\n",
    "# Back = number of previous data points to be used for forecasting\n",
    "Stock_Forecast(Instrument=\"EBL\", TRIAL=1000, PATIENCE=100, Back=60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
